{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def is_number(self):\n",
    "        if re.search(r'^\\d+$', self.val):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_contain_digit (self):\n",
    "        if re.search(r'\\d', self.val):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_date(self):\n",
    "        try: \n",
    "            parse(self.val, fuzzy=True)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    ls = []\n",
    "    sentence = re.sub(r'[.,]', ' ', sentence)\n",
    "    for word in re.split(r' +', sentence):\n",
    "        if word != '':\n",
    "            ls.append(Token(word))\n",
    "            \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(p):\n",
    "    ls = []\n",
    "    for s in re.split(r'\\n+',p):\n",
    "        if not re.match(r' +?$', s):\n",
    "            ls.append(s.strip())\n",
    "        \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(sentences):\n",
    "    ls = []\n",
    "    \n",
    "    sentences = tokenize(sentences)\n",
    "    for i in range(len(sentences)):\n",
    "        word = sentences[i].val\n",
    "        ls.append(f'{word}')\n",
    "    \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram(sentences):\n",
    "    ls = []\n",
    "    \n",
    "    sentences = f'<s> {sentences} </s>'\n",
    "    sentences = tokenize(sentences)\n",
    "    for i in range(len(sentences) - 1):\n",
    "        word = sentences[i].val\n",
    "        word_i = sentences[i + 1].val\n",
    "        ls.append(f'{word}_{word_i}')\n",
    "    \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram(sentences):\n",
    "    ls = []\n",
    "    \n",
    "    sentences = f'<s> <s> {sentences} </s> </s>'\n",
    "    sentences = tokenize(sentences)\n",
    "    \n",
    "    for i in range(len(sentences) - 2):\n",
    "        word = sentences[i].val\n",
    "        word_i = sentences[i + 1].val\n",
    "        word_ii = sentences[i + 2].val\n",
    "        ls.append(f'{word}_{word_i}_{word_ii}')\n",
    "    \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n_gram_dict(data):\n",
    "    unigram_dict = {}\n",
    "    bigram_dict = {}\n",
    "    trigram_dict = {}\n",
    "    N = 0\n",
    "    V = 0\n",
    "    \n",
    "    num_sentences = 0\n",
    "    for sentences in split_sentences(data):\n",
    "        num_sentences += 1\n",
    "        \n",
    "        for n_gram in unigram(sentences):\n",
    "            N += 1\n",
    "            if n_gram in unigram_dict:\n",
    "                unigram_dict[n_gram] += 1\n",
    "            else:\n",
    "                unigram_dict[n_gram] = 1\n",
    "                V += 1\n",
    "        \n",
    "        for n_gram in bigram(sentences):\n",
    "            if n_gram in bigram_dict:\n",
    "                bigram_dict[n_gram] += 1\n",
    "            else:\n",
    "                bigram_dict[n_gram] = 1\n",
    "                \n",
    "        for n_gram in trigram(sentences):\n",
    "            if n_gram in trigram_dict:\n",
    "                trigram_dict[n_gram] += 1\n",
    "            else:\n",
    "                trigram_dict[n_gram] = 1\n",
    "    \n",
    "    unigram_dict['</s>'] = num_sentences\n",
    "    return N, V, unigram_dict, bigram_dict, trigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_unigram(n_gram):\n",
    "    if n_gram in unigram_dict:\n",
    "        return unigram_dict[n_gram]/N\n",
    "    \n",
    "    return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_bigram(target, context, alpha=0, V=0):\n",
    "    part = context + '_' + target\n",
    "    \n",
    "    numerator = bigram_dict[part] if part in bigram_dict else 0\n",
    "    numerator += alpha\n",
    "    \n",
    "    denominator = unigram_dict[target] if target in unigram_dict else 0\n",
    "    denominator += V*alpha\n",
    "    \n",
    "    return 0 if denominator==0 else numerator/denominator    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_trigram(target, context, alpha=0, V=0):\n",
    "    part = context + '_' + target\n",
    "    \n",
    "    numerator = trigram_dict[part] if part in trigram_dict else 0\n",
    "    numerator += alpha\n",
    "    \n",
    "    denominator = unigram_dict[target] if target in unigram_dict else 0\n",
    "    denominator += V*alpha\n",
    "    \n",
    "\n",
    "    return 0 if denominator==0 else numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_bigram_sentences(sentences):\n",
    "#     Split sentences in to target and context.\n",
    "#     Multi all part and return value\n",
    "    \n",
    "    sentences = f'<s> {sentences} </s>' #padding\n",
    "    list_word = sentences.split()\n",
    "    len_sentences = list_word.__len__()\n",
    "    p_bigram = 1\n",
    "    \n",
    "    for i in range(1, len_sentences):\n",
    "        target = list_word[i]\n",
    "        context = list_word[i - 1]\n",
    "        p_bigram *= P_bigram(target, context)\n",
    "\n",
    "    return p_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_trigram_sentences(sentences):\n",
    "#     Split sentences in to target and context.\n",
    "#     Multi all part and return value\n",
    "    \n",
    "    sentences = f'<s> <s> {sentences} </s> </s>'  #padding\n",
    "    list_word = sentences.split()\n",
    "    len_sentences = list_word.__len__()\n",
    "    \n",
    "    p_trigram = 1\n",
    "\n",
    "    for i in range(2, len_sentences):\n",
    "        target = list_word[i]\n",
    "        context = list_word[i - 2] + '_' + list_word[i - 1]\n",
    "\n",
    "\n",
    "        p_trigram *= P_trigram(target, context)\n",
    "        \n",
    "    return p_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(sentences): \n",
    "#     Eval model by unseen text for both\n",
    "#     bigram and trigram. The less perplexity is,\n",
    "#     the better model becomes.\n",
    "    list_word = sentences.split()\n",
    "    len_sentences = list_word.__len__()\n",
    "    \n",
    "    #smooth\n",
    "    alpha = 1\n",
    "\n",
    "    #     for bigram\n",
    "    per_bigram = 1\n",
    "\n",
    "    for i in range(1, len_sentences):\n",
    "        target = list_word[i]\n",
    "        context = list_word[i - 1]\n",
    "\n",
    "        per_bigram *= 1/(P_bigram(target, context,  alpha, V))\n",
    "\n",
    "    per_bigram = pow(per_bigram, len_sentences)\n",
    "\n",
    "    # for trigram\n",
    "    per_trigram = 1\n",
    "\n",
    "    for i in range(2, len_sentences):\n",
    "        target = list_word[i]\n",
    "        context = list_word[i - 2] + '_' + list_word[i - 1]\n",
    "\n",
    "        per_trigram *= 1/(P_trigram(target, context, alpha, V))\n",
    "\n",
    "    per_trigram = pow(per_trigram, len_sentences)\n",
    "\n",
    "    return per_bigram, per_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_gram(text):\n",
    "    # TODO preprocess text\n",
    "    # \n",
    "    max_p_bigram = 0\n",
    "    word_bigram = 'none'\n",
    "    \n",
    "    max_p_trigram = 0\n",
    "    word_trigram = 'none'\n",
    "    \n",
    "    \n",
    "    for word in unigram_dict.keys():\n",
    "        p_bigram = P_bigram_sentences(text + ' ' + word)\n",
    "        p_trigram = P_trigram_sentences(text + ' ' + word)\n",
    "        \n",
    "        if p_bigram > max_p_bigram:\n",
    "            max_p_bigram = p_bigram \n",
    "            word_bigram = word\n",
    "            \n",
    "            \n",
    "        if p_trigram > max_p_trigram:\n",
    "            max_p_trigram = p_trigram \n",
    "            word_trigram = word\n",
    "            \n",
    "        \n",
    "    return f'bigram: {word_bigram}, trigram: {word_trigram}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-1-0c6840c28b17>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-0c6840c28b17>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    return f.read()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "with open(file_name) as f:\n",
    "    print(f.read())\n",
    "    # TODO: preprocess f.read()\n",
    "#     return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_name):\n",
    "    with open(file_name) as f:\n",
    "        # TODO: preprocess f.read()\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_dict = {}\n",
    "bigram_dict = {}\n",
    "trigram_dict = {}\n",
    "FILE_NAME = 'data_sample.txt'\n",
    "N = 0\n",
    "V = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     text_test = 'toi la hoc sinh'\n",
    "    \n",
    "    data = load(FILE_NAME)\n",
    "    N, V, unigram_dict, bigram_dict, trigram_dict = make_n_gram_dict(data)\n",
    "#     print(P_bigram_sentences())\n",
    "#     print(P_trigram_sentences())\n",
    "#     perplexity()\n",
    "#     next_gram('toi la hoc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigram: sinh, trigram: sinh'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
